{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ijGzTHJJUCPY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copyright 2024 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZPC2X_a9ErW7"
   },
   "source": [
    "# Getting Started with the Gemini API in Vertex AI with cURL / REST API\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_curl.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Run in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Fgetting-started%2Fintro_gemini_curl.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Run in Colab Enterprise\n",
    "    </a>\n",
    "  </td>       \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_curl.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/getting-started/intro_gemini_curl.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "   <td style=\"text-align: center\">\n",
    "    <a href=\"https://goo.gle/4jeQxSk\">\n",
    "      <img width=\"32px\" src=\"https://cdn.qwiklabs.com/assets/gcp_cloud-e3a77215f0b8bfa9b3f611c0d2208c7e8708ed31.svg\" alt=\"Google Cloud logo\"><br> Open in  Cloud Skills Boost\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n",
    "\n",
    "<div style=\"clear: both;\"></div>\n",
    "\n",
    "<b>Share to:</b>\n",
    "\n",
    "<a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_curl.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"LinkedIn logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://bsky.app/intent/compose?text=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_curl.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"Bluesky logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://twitter.com/intent/tweet?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_curl.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/5a/X_icon_2.svg\" alt=\"X logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://reddit.com/submit?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_curl.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_curl.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/51/Facebook_f_logo_%282019%29.svg\" alt=\"Facebook logo\">\n",
    "</a>            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f0cc0f48513b"
   },
   "source": [
    "| Author(s) |\n",
    "| --- |\n",
    "| [Eric Dong](https://github.com/gericdong) |\n",
    "| [Polong Lin](https://github.com/polong-lin) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "axauUzNXEl_R"
   },
   "source": [
    "## Overview\n",
    "\n",
    "**YouTube Video: Introduction to Gemini on Vertex AI**\n",
    "\n",
    "<a href=\"https://www.youtube.com/watch?v=YfiLUpNejpE&list=PLIivdWyY5sqJio2yeg1dlfILOUO2FoFRx\" target=\"_blank\">\n",
    "  <img src=\"https://img.youtube.com/vi/YfiLUpNejpE/maxresdefault.jpg\" alt=\"Introduction to Gemini on Vertex AI\" width=\"500\">\n",
    "</a>\n",
    "\n",
    "In this tutorial, you learn how to use the Vertex AI REST API with cURL commands to interact with the Gemini 2.0 Flash model.\n",
    "\n",
    "You will complete the following tasks:\n",
    "\n",
    "- Text generation\n",
    "- Streaming text generation\n",
    "- Chat\n",
    "- Function Calling\n",
    "- Multimodal Input\n",
    "- Controlled generation\n",
    "- Search as a tool\n",
    "- Code execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJf9sLIIEl_S"
   },
   "source": [
    "### Costs\n",
    "This tutorial uses billable components of Google Cloud:\n",
    "\n",
    "- Vertex AI\n",
    "\n",
    "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing) and use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D50ekWXjEl_S"
   },
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5f7c203ffaa1"
   },
   "source": [
    "### Install required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "4e66b2f6d36f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!sudo apt install -q jq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restart current runtime\n",
    "\n",
    "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which will restart the current kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Restart kernel after installs so that your environment can access the new packages\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. ⚠️</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmWOrTJ3gx13"
   },
   "source": [
    "### Authenticate your notebook environment (Colab only)\n",
    "\n",
    "If you are running this notebook on Google Colab, run the following cell to authenticate your environment.\n",
    "\n",
    "This step is not required if you are using [Vertex AI Workbench](https://cloud.google.com/vertex-ai-workbench)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "NyKGtVQjgx13",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Additional authentication is required for Google Colab\n",
    "if \"google.colab\" in sys.modules:\n",
    "    # Authenticate user to Google Cloud\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O6ZGaZlxP9L0"
   },
   "source": [
    "### Set Google Cloud project\n",
    "\n",
    "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
    "\n",
    "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "u8IivOG5SqY6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define project information\n",
    "PROJECT_ID = \"qwiklabs-gcp-01-cf97e3e1926f\"  # @param {type:\"string\"}\n",
    "LOCATION = \"europe-west1\"  # @param {type:\"string\"}\n",
    "\n",
    "# Import libraries\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "854fbf388e2b"
   },
   "source": [
    "## Use the Gemini 2.0 Flash model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7eeb063ac6d4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_ID = \"gemini-2.0-flash\"\n",
    "API_HOST = f\"{LOCATION}-aiplatform.googleapis.com\"\n",
    "\n",
    "os.environ[\"API_ENDPOINT\"] = (\n",
    "    f\"{API_HOST}/v1/projects/{PROJECT_ID}/locations/{LOCATION}/publishers/google/models/{MODEL_ID}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ZZUVBSzc0cR"
   },
   "source": [
    "## Text generation\n",
    "\n",
    "The `generateContent` method can handle a wide variety of use cases, including multi-turn chat and multimodal input, depending on what the underlying model supports. In this example, you send a text prompt and request the model response in text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1979afec8834",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sky is blue due to a phenomenon called **Rayleigh scattering**. Here's a breakdown of what that means:\n",
      "\n",
      "*   **Sunlight and its Colors:** Sunlight is actually made up of all the colors of the rainbow. These colors have different wavelengths. Blue and violet light have shorter wavelengths, while red and orange have longer wavelengths.\n",
      "\n",
      "*   **Entering the Atmosphere:** When sunlight enters the Earth's atmosphere, it collides with tiny air molecules (mostly nitrogen and oxygen).\n",
      "\n",
      "*   **Scattering:** This collision causes the light to scatter in different directions. The amount of scattering depends on the wavelength of the light.\n",
      "\n",
      "*   **Rayleigh Scattering Explained:** Rayleigh scattering is the scattering of electromagnetic radiation (like light) by particles of a much smaller wavelength. Because blue and violet light have shorter wavelengths, they are scattered much more strongly than longer wavelengths like red and orange (about 10 times more).\n",
      "\n",
      "*   **Why Blue and Not Violet?** While violet light is scattered even *more* than blue light, there are a couple of reasons why we see a blue sky:\n",
      "    *   **Sun's Emission:** The sun emits slightly less violet light than blue light.\n",
      "    *   **Our Eyes' Sensitivity:** Our eyes are more sensitive to blue light than violet light.\n",
      "    *   **Atmospheric Absorption:** The upper atmosphere absorbs some of the violet light.\n",
      "\n",
      "**In summary:** Blue light is scattered more effectively by the Earth's atmosphere than other colors, making the sky appear blue to our eyes.\n",
      "\n",
      "**Think of it like this:** Imagine throwing a bunch of ping pong balls (short wavelengths) and basketballs (long wavelengths) at a field full of small trees. The ping pong balls are much more likely to bounce off in random directions, filling the whole field, while the basketballs are more likely to go straight through.\n",
      "\n",
      "**Why are sunsets red?**\n",
      "\n",
      "At sunrise and sunset, the sunlight has to travel through more of the atmosphere to reach our eyes. This means that most of the blue light has already been scattered away by the time it reaches us. The longer wavelengths, like red and orange, are scattered less and can travel through the atmosphere more easily, giving us those beautiful sunset colors.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "curl -X POST \\\n",
    "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  https://${API_ENDPOINT}:generateContent \\\n",
    "  -d '{\n",
    "    \"contents\": {\n",
    "      \"role\": \"USER\",\n",
    "      \"parts\": { \"text\": \"Why is the sky blue?\" },\n",
    "    },\n",
    "    \"generation_config\": {\n",
    "      \"response_modalities\": \"TEXT\",\n",
    "     },\n",
    "  }' 2>/dev/null >response.json\n",
    "\n",
    "jq -r \".candidates[].content.parts[].text\" response.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "27701e417da6"
   },
   "source": [
    "### Streaming\n",
    "\n",
    "The Gemini API provides a streaming response mechanism. With this approach, you don't need to wait for the complete response; you can start processing fragments as soon as they're accessible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "rzkCij_iS0we",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The\n",
      " sky appears\n",
      " blue due to a phenomenon called **Rayleigh scattering**. Here's a breakdown\n",
      ":\n",
      "\n",
      "*   **Sunlight is White:** Sunlight is actually made up of all the\n",
      " colors of the rainbow.\n",
      "\n",
      "*   **Entering the Atmosphere:** When sunlight enters the Earth's atmosphere, it collides with tiny air molecules (mostly nitrogen and oxygen\n",
      ").\n",
      "\n",
      "*   **Scattering of Light:** This collision causes the sunlight to scatter in different directions.\n",
      "\n",
      "*   **Rayleigh Scattering:** Rayleigh scattering is the scattering of\n",
      " electromagnetic radiation (including light) by particles of a much smaller wavelength.\n",
      "\n",
      "*   **Blue Light is Scattered More:** Blue and violet light have shorter wavelengths than other colors.  Shorter wavelengths are scattered more effectively by these small air molecules than longer\n",
      " wavelengths (like red and orange).\n",
      "\n",
      "*   **Why Blue, Not Violet?:** Violet light is scattered even more than blue light. However, there are a couple of reasons why we see a blue sky instead of a violet sky:\n",
      "\n",
      "    *   The sun emits less violet light than blue light.\n",
      "    *   Our eyes are more sensitive to blue light than violet light.\n",
      "\n",
      "*   **Result:** Because blue light is scattered more effectively, it spreads out across the sky, making the sky appear blue to our eyes.\n",
      "\n",
      "In short, the sky\n",
      " is blue because air molecules scatter blue light from the sun more than they scatter other colors.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "curl -X POST \\\n",
    "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  https://${API_ENDPOINT}:streamGenerateContent \\\n",
    " \\\n",
    "  -d '{\n",
    "    \"contents\": {\n",
    "      \"role\": \"USER\",\n",
    "      \"parts\": { \"text\": \"Why is the sky blue?\" }\n",
    "    }\n",
    "  }' 2>/dev/null >response.json\n",
    "\n",
    "jq -r \".[] | .candidates[] | .content.parts[].text\" response.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3e56BV7PH9t8"
   },
   "source": [
    "### Model parameters\n",
    "\n",
    "Every prompt you send to the model includes parameter values that control how the model generates a response. The model can generate different results for different parameter values. You can experiment with different model parameters to see how the results change. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Px8hSHhiH9t8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lighthouse keeper, Silas, was a man woven from the sea itself. His skin was tanned and weathered like driftwood, his eyes the grey-green of a stormy horizon. He'd spent the last thirty years tending the beacon on Gull Rock, a jagged tooth of land miles from the mainland. He was content, or so he told himself.\n",
      "\n",
      "His only companion was a seagull named Bartholomew, a cheeky bird with a penchant for stealing Silas's lunch. Bartholomew was predictable, reliable, a constant in the swirling chaos of the ocean.\n",
      "\n",
      "One day, a storm unlike any Silas had ever seen descended. The wind howled like a banshee, tearing at the lighthouse walls. Waves crashed against the rock, sending plumes of spray high into the air, obscuring the light. Silas, seasoned as he was, felt a tremor of fear.\n",
      "\n",
      "Then, he saw it. A small, battered sailboat, tossed about like a toy in the monstrous waves. It was heading straight for the rocks.\n",
      "\n",
      "Silas knew he had to do something. He grabbed his oilskins and fought his way onto the narrow balcony, the wind nearly ripping him off his feet. He grabbed the foghorn cord and pulled, the mournful bellow echoing across the raging sea. He hoped, prayed, someone would hear.\n",
      "\n",
      "He watched, helpless, as the sailboat drew closer. He could make out a figure clinging to the mast, a young woman with long, dark hair plastered to her face.\n",
      "\n",
      "Just as the boat seemed destined to smash against the rocks, a miracle happened. A rogue wave, larger than any before, lifted the boat high, carrying it over the treacherous reef and into the relative calm of a small cove on the other side of the island.\n",
      "\n",
      "Silas, soaked and shivering, knew he had to reach her. He braved the storm again, scrambling down the winding stairs and out into the tempest. The path to the cove was treacherous, slick with seaweed and battered by the wind.\n",
      "\n",
      "He found her huddled beneath the overturned hull of the boat, shivering and terrified. Her name was Elara, and she was a marine biologist, studying the migratory patterns of whales. Her boat had been caught in the storm.\n",
      "\n",
      "Silas brought her back to the lighthouse, wrapped her in blankets, and gave her hot tea. As she warmed, she told him stories of the ocean's wonders, of the songs of whales and the bioluminescent glow of deep-sea creatures. Silas, in turn, told her tales of the sea's fury, of shipwrecks and near misses.\n",
      "\n",
      "For three days, they were stranded together, the storm raging outside. They talked, they laughed, they shared stories. Silas found himself looking at the world, and the sea, through Elara's eyes, seeing the beauty he had forgotten in his years of solitude.\n",
      "\n",
      "When the storm finally broke, a rescue boat arrived. Elara prepared to leave, but before she did, she turned to Silas. \"Thank you,\" she said, her eyes shining. \"You saved my life, and you reminded me of the power and beauty of the sea.\"\n",
      "\n",
      "She kissed him on the cheek, a fleeting touch that sent a jolt through him. As the boat pulled away, Silas watched her go, a strange ache in his chest.\n",
      "\n",
      "Life on Gull Rock returned to normal. Bartholomew stole his lunch, the waves crashed against the rocks, and the light continued to shine. But something had changed. Silas no longer felt quite so alone. He knew that somewhere out there, Elara was thinking of him, and he was thinking of her.\n",
      "\n",
      "He started to notice the small things again: the way the sunlight danced on the water, the intricate patterns of the seashells, the haunting cry of the gulls. He even started to learn the names of the different seabirds, inspired by Elara's passion.\n",
      "\n",
      "Silas was still the lighthouse keeper, a man woven from the sea. But now, he was also a man with a story to tell, a story of a storm, a rescue, and a connection that had bloomed in the heart of the ocean. And he knew, with a certainty that warmed him from the inside out, that he would never truly be alone again.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "curl -X POST \\\n",
    "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  https://${API_ENDPOINT}:generateContent \\\n",
    "  -d '{\n",
    "    \"contents\": {\n",
    "      \"role\": \"USER\",\n",
    "      \"parts\": [\n",
    "        {\"text\": \"Tell me a story.\"}\n",
    "      ]\n",
    "    },\n",
    "    \"generation_config\": {\n",
    "      \"temperature\": 0.2,\n",
    "      \"top_p\": 0.1,\n",
    "      \"top_k\": 16,\n",
    "      \"max_output_tokens\": 2048,\n",
    "      \"candidate_count\": 1,\n",
    "      \"stop_sequences\": []\n",
    "    },\n",
    "    \"safety_settings\": {\n",
    "      \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "      \"threshold\": \"BLOCK_LOW_AND_ABOVE\"\n",
    "    }\n",
    "  }' 2>/dev/null >response.json\n",
    "\n",
    "jq -r \".candidates[].content.parts[].text\" response.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I4-XhmPn_Pb-"
   },
   "source": [
    "### Chat\n",
    "\n",
    "The Gemini API supports natural multi-turn conversations and is ideal for text tasks that require back-and-forth interactions.\n",
    "\n",
    "Specify the `role` field only if the content represents a turn in a conversation. You can set `role` to one of the following values: `user`, `model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "YqSQSK-K-KVU",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alright, let's get down to business!  To best determine the \"first order of business,\" I need a little more context. Could you tell me:\n",
      "\n",
      "*   **What is the context of this \"meeting\" or interaction?** Are we planning a project, discussing a problem, working on a task, or just having a casual chat?\n",
      "*   **What are our goals for this interaction?** What do you want to accomplish?\n",
      "\n",
      "Once I have a better understanding of the situation, I can help you determine the most important thing to address first.\n",
      "\n",
      "In the absence of that context, I'll offer some general possibilities:\n",
      "\n",
      "1.  **Confirming the Agenda:**  \"First, we should probably agree on an agenda for our conversation. What would you like to cover today?\"\n",
      "2.  **Defining the Purpose:** \"First, let's make sure we're all on the same page about the purpose of this discussion.\"\n",
      "3.  **Quick Introductions:** \"If we haven't already, let's do a quick round of introductions.\"\n",
      "4.  **Reviewing Action Items (if applicable):** \"Before we dive in, let's quickly review any outstanding action items from our last meeting/conversation.\"\n",
      "\n",
      "Let me know which of these, if any, feel right, or give me more information so I can give you a more relevant answer!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "curl -X POST \\\n",
    "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  https://${API_ENDPOINT}:generateContent \\\n",
    "  -d '{\n",
    "    \"contents\": [\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"parts\": [\n",
    "          { \"text\": \"Hello\" }\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"role\": \"model\",\n",
    "        \"parts\": [\n",
    "          { \"text\": \"Hello! I am glad you could both make it.\" }\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"parts\": [\n",
    "          { \"text\": \"So what is the first order of business?\" }\n",
    "        ]\n",
    "      }\n",
    "    ]\n",
    "  }' 2>/dev/null >response.json\n",
    "\n",
    "jq -r \".candidates[].content.parts[].text\" response.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5f0f5fe3b331"
   },
   "source": [
    "### Function calling\n",
    "\n",
    "Function calling lets you create a description of a function in their code, then pass that description to a language model in a request. This sample is an example of passing in a description of a function that returns information about where a movie is playing. Several function declarations are included in the request, such as `find_movies` and `find_theaters`.\n",
    "\n",
    "Learn more about [function calling](https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/function-calling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "680b11b0ba4c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"find_theaters\",\n",
      "  \"args\": {\n",
      "    \"location\": \"Mountain View, CA\",\n",
      "    \"movie\": \"Barbie\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "curl -X POST \\\n",
    "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  https://${API_ENDPOINT}:generateContent \\\n",
    "  -d '{\n",
    "  \"contents\": {\n",
    "    \"role\": \"user\",\n",
    "    \"parts\": {\n",
    "      \"text\": \"Which theaters in Mountain View show Barbie movie?\"\n",
    "    }\n",
    "  },\n",
    "  \"tools\": [\n",
    "    {\n",
    "      \"function_declarations\": [\n",
    "        {\n",
    "          \"name\": \"find_movies\",\n",
    "          \"description\": \"find movie titles currently playing in theaters based on any description, genre, title words, etc.\",\n",
    "          \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "              \"location\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city and state, e.g. San Francisco, CA or a zip code e.g. 95616\"\n",
    "              },\n",
    "              \"description\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Any kind of description including category or genre, title words, attributes, etc.\"\n",
    "              }\n",
    "            },\n",
    "            \"required\": [\n",
    "              \"description\"\n",
    "            ]\n",
    "          }\n",
    "        },\n",
    "        {\n",
    "          \"name\": \"find_theaters\",\n",
    "          \"description\": \"find theaters based on location and optionally movie title which are is currently playing in theaters\",\n",
    "          \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "              \"location\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city and state, e.g. San Francisco, CA or a zip code e.g. 95616\"\n",
    "              },\n",
    "              \"movie\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Any movie title\"\n",
    "              }\n",
    "            },\n",
    "            \"required\": [\n",
    "              \"location\"\n",
    "            ]\n",
    "          }\n",
    "        },\n",
    "        {\n",
    "          \"name\": \"get_showtimes\",\n",
    "          \"description\": \"Find the start times for movies playing in a specific theater\",\n",
    "          \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "              \"location\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city and state, e.g. San Francisco, CA or a zip code e.g. 95616\"\n",
    "              },\n",
    "              \"movie\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Any movie title\"\n",
    "              },\n",
    "              \"theater\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Name of theater\"\n",
    "              },\n",
    "              \"date\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Date for requested showtime\"\n",
    "              }\n",
    "            },\n",
    "            \"required\": [\n",
    "              \"location\",\n",
    "              \"movie\",\n",
    "              \"theater\",\n",
    "              \"date\"\n",
    "            ]\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}' 2>/dev/null >response.json\n",
    "\n",
    "jq -r \".candidates[].content.parts[].functionCall\" response.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R3g5n23lDtsN"
   },
   "source": [
    "## Multimodal input\n",
    "\n",
    "Gemini is a multimodal model that supports adding image and video in text or chat prompts for a text response.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uTfL2DDch4Lp"
   },
   "source": [
    "### Download an image from Google Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "KmtWSNLtJ7oD",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://cloud-samples-data/generative-ai/image/320px-Felis_catus-cat_on_snow.jpg...\n",
      "/ [1 files][ 17.4 KiB/ 17.4 KiB]                                                \n",
      "Operation completed over 1 objects/17.4 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "! gsutil cp \"gs://cloud-samples-data/generative-ai/image/320px-Felis_catus-cat_on_snow.jpg\" ./image.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BlyyaPgmhpyv"
   },
   "source": [
    "### Generate text from a local image\n",
    "\n",
    "Specify the [base64](https://en.wikipedia.org/wiki/Base64) encoding of the image or video to include inline in the prompt and the `mime_type` field. The supported [MIME types](https://en.wikipedia.org/wiki/Media_type) for images include `image/png` and `image/jpeg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "-uqZ-RWdtdit",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, that is a cat. It appears to be a brown tabby cat.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Encode image data in base64\n",
    "image_file=\"image.jpg\"\n",
    "if [[ -f \"$image_file\" ]]; then\n",
    "  if command -v base64 &> /dev/null; then\n",
    "    # base64 is available\n",
    "    if [[ \"$(uname -s)\" == \"Darwin\" ]]; then\n",
    "      # macOS -b 0 to avoid line wrapping\n",
    "      data=$(base64 -b 0 -i \"$image_file\")\n",
    "    else\n",
    "      # Linux -w 0 to avoid line wrapping\n",
    "      data=$(base64 -w 0 \"$image_file\")\n",
    "    fi\n",
    "  else\n",
    "    echo \"Error: base64 command not found.\"\n",
    "    exit 1\n",
    "  fi\n",
    "else\n",
    "  echo \"Error: Image file '$image_file' not found.\"\n",
    "  exit 1\n",
    "fi\n",
    "\n",
    "curl -X POST \\\n",
    "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  https://${API_ENDPOINT}:generateContent \\\n",
    "  -d \"{\n",
    "      'contents': {\n",
    "        'role': 'USER',\n",
    "        'parts': [\n",
    "          {\n",
    "            'text': 'Is it a cat?'\n",
    "          },\n",
    "          {\n",
    "            'inline_data': {\n",
    "              'data': '${data}',\n",
    "              'mime_type':'image/jpeg'\n",
    "            }\n",
    "          }\n",
    "        ]\n",
    "       }\n",
    "    }\" 2>/dev/null >response.json\n",
    "\n",
    "jq -r \".candidates[].content.parts[].text\" response.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKr-BklmhjgP"
   },
   "source": [
    "### Generate text from an image on Google Cloud Storage\n",
    "\n",
    "Specify the Cloud Storage URI of the image to include in the prompt. The bucket that stores the file must be in the same Google Cloud project that's sending the request. You must also specify the `mime_type` field. The supported image MIME types include `image/png` and `image/jpeg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "43pQE3_z3OjG",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a description of the image:\n",
      "\n",
      "**Overall Impression:**\n",
      "\n",
      "The image shows a tabby cat standing in the snow. The cat is the main subject and is in focus, while the snowy background is slightly blurred.\n",
      "\n",
      "**Cat's Appearance:**\n",
      "\n",
      "*   **Coat:** The cat has a classic tabby coat pattern, with dark brown or black stripes on a lighter brown background.\n",
      "*   **Eyes:** The cat has yellow or golden eyes.\n",
      "*   **Pose:** The cat is standing with one paw slightly raised, as if it's about to take a step. It's looking directly at the camera with a curious or alert expression.\n",
      "*   **Build:** The cat appears to be of average build, neither overly thin nor overweight.\n",
      "\n",
      "**Background:**\n",
      "\n",
      "*   The background is entirely snow-covered.\n",
      "*   There are some subtle textures and variations in the snow, suggesting it might be a path or a field.\n",
      "*   The background is out of focus, which helps to emphasize the cat as the main subject.\n",
      "\n",
      "**Overall Tone:**\n",
      "\n",
      "The image has a natural and slightly cold feel due to the snow. The cat's alert expression adds a touch of curiosity and liveliness to the scene.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "curl -X POST \\\n",
    "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  https://${API_ENDPOINT}:generateContent \\\n",
    "  -d '{\n",
    "    \"contents\": {\n",
    "      \"role\": \"USER\",\n",
    "      \"parts\": [\n",
    "        {\n",
    "          \"text\": \"Describe this image\"\n",
    "        },\n",
    "        {\n",
    "          \"file_data\": {\n",
    "            \"mime_type\": \"image/png\",\n",
    "            \"file_uri\": \"gs://cloud-samples-data/generative-ai/image/320px-Felis_catus-cat_on_snow.jpg\"\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    \"generation_config\": {\n",
    "      \"temperature\": 0.2,\n",
    "      \"top_p\": 0.1,\n",
    "      \"top_k\": 16,\n",
    "      \"max_output_tokens\": 2048,\n",
    "      \"candidate_count\": 1,\n",
    "      \"stop_sequences\": []\n",
    "    },\n",
    "    \"safety_settings\": {\n",
    "      \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "      \"threshold\": \"BLOCK_LOW_AND_ABOVE\"\n",
    "    }\n",
    "  }' 2>/dev/null >response.json\n",
    "\n",
    "jq -r \".candidates[].content.parts[].text\" response.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TVF4vHuBOD8N"
   },
   "source": [
    "### Generate text from a video file\n",
    "\n",
    "Specify the Cloud Storage URI of the video to include in the prompt. The bucket that stores the file must be in the same Google Cloud project that's sending the request. You must also specify the `mime_type` field. The supported MIME types for video include `video/mp4`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "F8kS5p0l_uHE",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, here's the information from the video:\n",
      "\n",
      "*   **Profession of the main person:** Photographer\n",
      "*   **Main features of the phone highlighted:** 'Video Boost' and 'Night Sight', which enhances image quality in low light.\n",
      "*   **City this was recorded in:** Tokyo, Japan\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "curl -X POST \\\n",
    "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  https://${API_ENDPOINT}:generateContent \\\n",
    "  -d \\\n",
    "'{\n",
    "    \"contents\": {\n",
    "      \"role\": \"USER\",\n",
    "      \"parts\": [\n",
    "        {\n",
    "          \"text\": \"Answer the following questions using the video only. What is the profession of the main person? What are the main features of the phone highlighted? Which city was this recorded in?\"\n",
    "        },\n",
    "        {\n",
    "          \"file_data\": {\n",
    "            \"mime_type\": \"video/mp4\",\n",
    "            \"file_uri\": \"gs://github-repo/img/gemini/multimodality_usecases_overview/pixel8.mp4\"\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  }' 2>/dev/null >response.json\n",
    "\n",
    "jq -r \".candidates[].content.parts[].text\" response.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "133ddb1bc7ff"
   },
   "source": [
    "### Controlled Generation\n",
    "\n",
    "Controlled generation allows you to define a response schema to specify the structure of a model's output, the field names, and the expected data type for each field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "40db1e8d9061",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"recipe_name\": \"Chocolate Chip Cookies\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "curl -X POST \\\n",
    "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  https://${API_ENDPOINT}:generateContent \\\n",
    "  -d '{\n",
    "    \"contents\": {\n",
    "      \"role\": \"user\",\n",
    "      \"parts\": {\n",
    "        \"text\": \"List a few popular cookie recipes.\"\n",
    "      }\n",
    "    },\n",
    "    \"generationConfig\": {\n",
    "        \"response_mime_type\": \"application/json\",\n",
    "        \"response_schema\": {\"type\": \"object\", \"properties\": {\"recipe_name\": {\"type\": \"string\"}}}\n",
    "    },\n",
    "}' 2>/dev/null >response.json\n",
    "\n",
    "jq -r \".candidates[].content.parts[].text\" response.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ebcbb1533401"
   },
   "source": [
    "## Search as a tool\n",
    "\n",
    "Using Grounding with Google Search, you can improve the accuracy and recency of responses from the model. Starting with Gemini 2.0, Google Search is available as a tool. This means that the model can decide when to use Google Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "a3d8a66bfb3c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weather in San Jose, CA today, May 13, 2025, is cloudy with a temperature of 56°F (13°C), but it feels like 55°F (13°C). The humidity is around 72%.\n",
      "\n",
      "Here's a more detailed forecast for today and the coming days:\n",
      "\n",
      "*   **Today:** Mostly cloudy in the morning, becoming sunny in the afternoon with a high near 70°F. There is a slight chance of drizzle after 11 am. Northwest winds will be 5 to 15 mph.\n",
      "*   **Tonight:** Mostly clear with a low around 48°F. Northwest winds of 10 to 15 mph, decreasing to around 5 mph after midnight.\n",
      "*   **Wednesday:** Sunny with a high near 77°F. Light winds becoming northwest 5 to 10 mph in the afternoon.\n",
      "*   **Wednesday Night:** Mostly clear with a low around 48°F. Northwest winds of 10 to 15 mph in the evening, becoming light.\n",
      "*   **Thursday:** Sunny with a high around 81°F.\n",
      "*   **Thursday Night:** Partly cloudy in the evening, becoming mostly cloudy with a low in the lower 50s.\n",
      "*   **Friday:** Mostly sunny, with a high near 77°F.\n",
      "\n",
      "[\n",
      "  {\n",
      "    \"web\": {\n",
      "      \"uri\": \"https://www.google.com/search?q=weather+in+San Jose,+CA\",\n",
      "      \"title\": \"Weather information for locality: San Jose, administrative_area: CA\",\n",
      "      \"domain\": \"google.com\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"web\": {\n",
      "      \"uri\": \"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXGDiNy7sCclKm3QqJP-WuFwEOmJ9-8vsCgfWp_SkWe_nIjne0DHl3DAkdDqqC1YzCjSQzNLjjE2Gtmlcplw2YKMooDvn2OcjZjPsYnlzLeT2EdbDwpmR47OCU6UTxtDZI5pD7drmraJDzuHCLFl0BeU46v5wRcG9al8aXtA9g==\",\n",
      "      \"title\": \"weather.gov\",\n",
      "      \"domain\": \"weather.gov\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"web\": {\n",
      "      \"uri\": \"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXFU2Jm-DR8h13E7xaTCwQ9DTNukG6Y25vTibgFXAtI3ozL1a9L1_aYQcXS4l8Zhj9af9Jtc86dgXwIQKwZlsAvRwjUJe1yYwzqZ4-GWYAsoZvQnPxaeogBsfGjlNRihzy4bJOXfgy-s7XaZZn3DR-K93w==\",\n",
      "      \"title\": \"weather.gov\",\n",
      "      \"domain\": \"weather.gov\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"web\": {\n",
      "      \"uri\": \"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXFhujUbmWpdDUHVi4_rwQNdNS3Y6d3YfW4-w9vFA4tF1AffBqhJn_zUQyXwm9hDDkYTdzrnape8zW9QNf09ZoK_WqxAEKv5uocLHUEj3e1EJBMmV642OkkGg1aMXdYge3pIwwEDxLpxMULO\",\n",
      "      \"title\": \"weatherforyou.com\",\n",
      "      \"domain\": \"weatherforyou.com\"\n",
      "    }\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "curl -X POST \\\n",
    "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  https://${API_ENDPOINT}:generateContent \\\n",
    "  -d '{\n",
    "    \"contents\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"parts\": [\n",
    "                {\n",
    "                    \"text\": \"What is the weather today in San Jose CA?\"\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "  ],\n",
    "  \"tools\": {\n",
    "     \"google_search\": {}\n",
    "  },\n",
    "  \"generationConfig\": {\n",
    "      \"response_modalities\": \"TEXT\"\n",
    "  }\n",
    "}' 2>/dev/null >response.json\n",
    "\n",
    "jq -r \".candidates[].content.parts[].text\" response.json\n",
    "jq -r \".candidates[].groundingMetadata.groundingChunks\" response.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "37223c8e3133"
   },
   "source": [
    "### Code Execution\n",
    "\n",
    "The Gemini API code execution feature enables the model to generate and run Python code and learn iteratively from the results until it arrives at a final output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "7cebe2cd31c1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"text\": \"Okay, I can do that. First, I'll calculate the 20th Fibonacci number. Then, I'll find the nearest palindrome to it.\\n\\n\"\n",
      "}\n",
      "{\n",
      "  \"executableCode\": {\n",
      "    \"language\": \"PYTHON\",\n",
      "    \"code\": \"def fibonacci(n):\\n    if n <= 0:\\n        return 0\\n    elif n == 1:\\n        return 1\\n    else:\\n        a, b = 0, 1\\n        for _ in range(2, n + 1):\\n            a, b = b, a + b\\n        return b\\n\\nfib_20 = fibonacci(20)\\nprint(f'{fib_20=}')\\n\"\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"codeExecutionResult\": {\n",
      "    \"outcome\": \"OUTCOME_OK\",\n",
      "    \"output\": \"fib_20=6765\\n\"\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"text\": \"The 20th Fibonacci number is 6765. Now, I need to find the nearest palindrome. The closest palindromes will be numbers that read the same forwards and backward and are close to 6765. I will check palindromes above and below 6765.\\n\\nPalindromes around 6765 could be 6666, 6776, 6886, 6996, 6565 etc. Let's compute the absolute differences between 6765 and some palindromes.\\n\\n\"\n",
      "}\n",
      "{\n",
      "  \"executableCode\": {\n",
      "    \"language\": \"PYTHON\",\n",
      "    \"code\": \"number = 6765\\npalindromes = [6565, 6666, 6776, 6886, 6996]\\ndifferences = [abs(number - p) for p in palindromes]\\nprint(f'{differences=}')\\n\"\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"codeExecutionResult\": {\n",
      "    \"outcome\": \"OUTCOME_OK\",\n",
      "    \"output\": \"differences=[200, 99, 11, 121, 231]\\n\"\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"text\": \"The differences are 200, 99, 11, 121, and 231. The smallest difference is 11, which corresponds to the palindrome 6776. Therefore, the nearest palindrome to 6765 is 6776.\\n\\nFinal Answer: The final answer is $\\\\boxed{6776}$\\n\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "curl -X POST \\\n",
    "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  https://${API_ENDPOINT}:generateContent \\\n",
    "  -d '{\n",
    "  \"contents\": {\n",
    "    \"role\": \"user\",\n",
    "    \"parts\": {\n",
    "      \"text\": \"Calculate 20th fibonacci number. Then find the nearest palindrome to it.\"\n",
    "    }\n",
    "  },\n",
    "  \"tools\": [\n",
    "      {\"code_execution\": {},}\n",
    "  ]\n",
    "}' 2>/dev/null >response.json\n",
    "\n",
    "jq -r \".candidates[].content.parts[]\" response.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6301d8abe89d"
   },
   "source": [
    "## What's next\n",
    "\n",
    "- Explore other notebooks in the [Google Cloud Generative AI GitHub repository](https://github.com/GoogleCloudPlatform/generative-ai).\n",
    "- Explore AI models in [Model Garden](https://cloud.google.com/vertex-ai/generative-ai/docs/model-garden/explore-models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "intro_gemini_curl.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
