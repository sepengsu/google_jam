{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6313d1b2-6049-4263-ad18-b8eaa8be6ca8",
   "metadata": {},
   "source": [
    "### Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dc712ca-6612-4339-ab56-60c5eef36775",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 05:33:00.265847: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-14 05:33:00.270971: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-14 05:33:00.286057: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747200780.311662   48916 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747200780.319143   48916 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1747200780.352038   48916 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747200780.352088   48916 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747200780.352091   48916 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747200780.352094   48916 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-14 05:33:00.364583: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-14 05:33:06.340180: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m   5/1875\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 14ms/step - loss: 2.1979 - sparse_categorical_accuracy: 0.1721  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 05:33:09.332070: I tensorflow/core/kernels/data/tf_record_dataset_op.cc:387] The default buffer size is 262144, which is overridden by the user specified `buffer_size` of 8388608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - loss: 0.6608 - sparse_categorical_accuracy: 0.7714\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.4065 - sparse_categorical_accuracy: 0.8568\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - loss: 0.3624 - sparse_categorical_accuracy: 0.8697\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - loss: 0.3353 - sparse_categorical_accuracy: 0.8797\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.3152 - sparse_categorical_accuracy: 0.8860\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:upLogger:Model: \"sequential\"\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
      "┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
      "│ flatten (Flatten)               │ (None, 784)            │             0 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dense (Dense)                   │ (None, 64)             │        50,240 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dense_1 (Dense)                 │ (None, 10)             │           650 │\n",
      "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
      " Total params: 152,672 (596.38 KB)\n",
      " Trainable params: 50,890 (198.79 KB)\n",
      " Non-trainable params: 0 (0.00 B)\n",
      " Optimizer params: 101,782 (397.59 KB)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import and configure logging\n",
    "import logging\n",
    "import google.cloud.logging as cloud_logging\n",
    "from google.cloud.logging.handlers import CloudLoggingHandler\n",
    "from google.cloud.logging_v2.handlers import setup_logging\n",
    "up_logger = logging.getLogger('upLogger')\n",
    "up_logger.setLevel(logging.INFO)\n",
    "up_logger.addHandler(CloudLoggingHandler(cloud_logging.Client(), name=\"updated\"))\n",
    "\n",
    "# Import tensorflow_datasets\n",
    "import tensorflow_datasets as tfds\n",
    "# Import numpy\n",
    "import numpy as np\n",
    "# Import TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define, load and configure data\n",
    "(ds_train, ds_test), info = tfds.load('fashion_mnist', split=['train', 'test'], with_info=True, as_supervised=True)\n",
    "# Define batch size\n",
    "BATCH_SIZE = 32\n",
    "# Normalizing and batch processing of data\n",
    "ds_train = ds_train.map(lambda x, y: (tf.cast(x, tf.float32)/255.0, y)).batch(BATCH_SIZE)\n",
    "ds_test = ds_test.map(lambda x, y: (tf.cast(x, tf.float32)/255.0, y)).batch(BATCH_SIZE)\n",
    "# Define the model\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "# Compile data\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "              loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "model.fit(ds_train, epochs=5)\n",
    "# Logs model summary\n",
    "model.summary(print_fn=up_logger.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d310d73-fa7e-4730-8dd1-bd2c0d179a4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - loss: 0.6226 - sparse_categorical_accuracy: 0.7820\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - loss: 0.3846 - sparse_categorical_accuracy: 0.8627\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - loss: 0.3414 - sparse_categorical_accuracy: 0.8761\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - loss: 0.3144 - sparse_categorical_accuracy: 0.8862\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - loss: 0.2957 - sparse_categorical_accuracy: 0.8914\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:upLogger:Model: \"sequential_1\"\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
      "┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
      "│ flatten_1 (Flatten)             │ (None, 784)            │             0 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dense_2 (Dense)                 │ (None, 128)            │       100,480 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dense_3 (Dense)                 │ (None, 10)             │         1,290 │\n",
      "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
      " Total params: 305,312 (1.16 MB)\n",
      " Trainable params: 101,770 (397.54 KB)\n",
      " Non-trainable params: 0 (0.00 B)\n",
      " Optimizer params: 203,542 (795.09 KB)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "# Compile data\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "              loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "model.fit(ds_train, epochs=5)\n",
    "# Logs model summary\n",
    "model.summary(print_fn=up_logger.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163bcd66-e00d-48ca-8f86-0aa6b5a8ea09",
   "metadata": {},
   "source": [
    "### Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f220716a-cd2e-493b-8d36-f47746c18054",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - loss: 0.6499 - sparse_categorical_accuracy: 0.7733\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - loss: 0.3844 - sparse_categorical_accuracy: 0.8634\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.3426 - sparse_categorical_accuracy: 0.8753\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.3204 - sparse_categorical_accuracy: 0.8828\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.3027 - sparse_categorical_accuracy: 0.8891\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:upLogger:Model: \"sequential_2\"\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
      "┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
      "│ flatten_2 (Flatten)             │ (None, 784)            │             0 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dense_4 (Dense)                 │ (None, 64)             │        50,240 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dense_5 (Dense)                 │ (None, 64)             │         4,160 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dense_6 (Dense)                 │ (None, 10)             │           650 │\n",
      "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
      " Total params: 165,152 (645.13 KB)\n",
      " Trainable params: 55,050 (215.04 KB)\n",
      " Non-trainable params: 0 (0.00 B)\n",
      " Optimizer params: 110,102 (430.09 KB)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "# Compile data\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "              loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "model.fit(ds_train, epochs=5)\n",
    "# Logs model summary\n",
    "model.summary(print_fn=up_logger.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6197ba5-b7de-429c-97f8-3c7d290e212f",
   "metadata": {},
   "source": [
    "### Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ac88a27-1ffb-42d4-994e-f3f70c857822",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - loss: 9.2829 - sparse_categorical_accuracy: 0.6191\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - loss: 0.8200 - sparse_categorical_accuracy: 0.7000\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.7078 - sparse_categorical_accuracy: 0.7404\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.6312 - sparse_categorical_accuracy: 0.7750\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.5777 - sparse_categorical_accuracy: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:upLogger:Model: \"sequential_3\"\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
      "┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
      "│ flatten_3 (Flatten)             │ (None, 784)            │             0 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dense_7 (Dense)                 │ (None, 64)             │        50,240 │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
      "│ dense_8 (Dense)                 │ (None, 10)             │           650 │\n",
      "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
      " Total params: 152,672 (596.38 KB)\n",
      " Trainable params: 50,890 (198.79 KB)\n",
      " Non-trainable params: 0 (0.00 B)\n",
      " Optimizer params: 101,782 (397.59 KB)\n",
      "\n",
      "2025-05-14 05:38:25.142336: W tensorflow/core/kernels/data/cache_dataset_ops.cc:916] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "INFO:upLogger:training images max 255\n",
      "INFO:upLogger:test images max 255\n"
     ]
    }
   ],
   "source": [
    "# Import and configure logging\n",
    "import logging\n",
    "import google.cloud.logging as cloud_logging\n",
    "from google.cloud.logging.handlers import CloudLoggingHandler\n",
    "from google.cloud.logging_v2.handlers import setup_logging\n",
    "up_logger = logging.getLogger('upLogger')\n",
    "up_logger.setLevel(logging.INFO)\n",
    "up_logger.addHandler(CloudLoggingHandler(cloud_logging.Client(), name=\"updated\"))\n",
    "\n",
    "# Import tensorflow_datasets\n",
    "import tensorflow_datasets as tfds\n",
    "# Import numpy\n",
    "import numpy as np\n",
    "# Import TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define, load and configure data\n",
    "(ds_train, ds_test), info = tfds.load('fashion_mnist', split=['train', 'test'], with_info=True, as_supervised=True)\n",
    "# Define batch size\n",
    "BATCH_SIZE = 32\n",
    "# Normalizing and batch processing of data\n",
    "ds_train = ds_train.batch(BATCH_SIZE)\n",
    "ds_test = ds_test.batch(BATCH_SIZE)\n",
    "# Define the model\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "# Compile data\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "              loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "model.fit(ds_train, epochs=5)\n",
    "# Logs model summary\n",
    "model.summary(print_fn=up_logger.info)\n",
    "\n",
    "# Print out max value to see the changes\n",
    "image_batch, labels_batch = next(iter(ds_train))\n",
    "t_image_batch, t_labels_batch = next(iter(ds_test))\n",
    "up_logger.info(\"training images max \" + str(np.max(image_batch[0])))\n",
    "up_logger.info(\"test images max \" + str(np.max(t_image_batch[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125959d7-82be-48fe-8e9c-a50db5ab1de9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
